{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import json\n",
    "from spacy.lemmatizer import Lemmatizer, ADJ, NOUN, VERB\n",
    "\n",
    "lemmatizer = nlp.vocab.morphology.lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextualEntailment\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "fileList=['TextualEntailment']\n",
    "resultDf=pd.DataFrame()\n",
    "for num,fileName in enumerate(fileList):\n",
    "    print(fileName)\n",
    "    dfs=pd.read_excel(\"FinalDatasetAuto\"+fileName+\".xlsx\",index_col=0)\n",
    "    dfs=dfs[427:]\n",
    "    dfs=dfs.reset_index(drop=True)\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        if dfs.loc[index,'adj/noun-label']=='N':\n",
    "            dfs.loc[index,'arg0']=''\n",
    "            dfs.loc[index,'arg1']=''\n",
    "            dfs.loc[index,'V']=''\n",
    "            dfs.loc[index,'baseV']=''\n",
    "            dfs.loc[index,'PP']=''\n",
    "    dfs['arg0']=dfs['arg0'].replace(np.NaN,'')\n",
    "    dfs['arg1']=dfs['arg1'].replace(np.NaN,'')\n",
    "    dfs['PP']=dfs['PP'].replace(np.NaN,'')\n",
    "    columnList=['arg0','V','arg1','PP']\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        result=''\n",
    "        for column in columnList:\n",
    "            if dfs.loc[index,column]!='':\n",
    "                    result=result+dfs.loc[index,column]+\" \"\n",
    "        dfs.loc[index,'gold']=result\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        if index+1<len(dfs['adj/noun']) and dfs.loc[index,'adj/noun']==dfs.loc[index+1,'adj/noun'] and dfs.loc[index,'n_v']==dfs.loc[index+1,'n_v'] and dfs.loc[index,'prep']==dfs.loc[index+1,'prep'] and dfs.loc[index,'pobj']==dfs.loc[index+1,'pobj']:\n",
    "            dfs.loc[index,'gold2']=dfs.loc[index+1,'gold']\n",
    "        else:\n",
    "            dfs.loc[index,'gold2']=dfs.loc[index,'gold']\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        if dfs.loc[index,'HighestScorePattern']=='M' or dfs.loc[index,'HighestScorePattern']=='OVB' or dfs.loc[index,'HighestScorePattern']=='VOB' or dfs.loc[index,'HighestScorePattern']=='V1' or dfs.loc[index,'HighestScorePattern']=='V2':\n",
    "            tempDict=dfs.loc[index,'MVOScore':'OVpMPassiveScore'].to_dict()\n",
    "            tempDict={k: v for k, v in tempDict.items() if str(v) != 'nan' and k!='HighestScorePattern' and k!='MScore' and k!='V1Score' and k!='V2Score'}\n",
    "            dfs.loc[index,'HighestScorePattern']=max(tempDict.items(), key=operator.itemgetter(1))[0][:-5]\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        my_dict=dfs.loc[index,'MVOScore':'OVpMPassiveScore'].to_dict()\n",
    "        my_dict={k: v for k, v in my_dict.items() if str(v) != 'nan' and k!='HighestScorePattern' and k!='MScore' and k!='V1Score' and k!='V2Score'}\n",
    "        highestScorePatternList=sorted(my_dict, key=my_dict.get, reverse=True)[:3]\n",
    "        dfs.loc[index,'HighestScorePattern']=\",\".join(highestScorePatternList)\n",
    "    dfs.to_excel(\"FinalDatasetAuto\"+fileName+\"Top3RemoveArticleMetric.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
